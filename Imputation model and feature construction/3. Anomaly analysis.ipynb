{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a401720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: polars in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 2)) (1.35.2)\n",
      "Requirement already satisfied: fastexcel in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 3)) (0.17.2)\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 4)) (22.0.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 5)) (3.10.7)\n",
      "Requirement already satisfied: holidays in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 6)) (0.85)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 7)) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: polarify in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 10)) (0.2.1)\n",
      "Requirement already satisfied: livelossplot in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 11)) (0.5.6)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 12)) (2.3.5)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 13)) (2.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in ./.venv/lib/python3.14/site-packages (from polars->-r requirements.txt (line 2)) (1.35.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: bokeh in ./.venv/lib/python3.14/site-packages (from livelossplot->-r requirements.txt (line 11)) (3.8.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.5.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.14/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.13 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (2.12.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (6.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (6.5.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (2025.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.14/site-packages (from jinja2->torch->-r requirements.txt (line 13)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba518a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from livelossplot import PlotLosses\n",
    "import random\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb6da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeImputerNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_impute_features: int,\n",
    "        n_time_features: int,\n",
    "        n_lags: int,\n",
    "        hidden_sizes: Sequence[int] = (128, 64),\n",
    "        know_whats_hidden: bool = False,\n",
    "        lag_list: Sequence[int] | None = None,\n",
    "        impute_var_names: Sequence[str] | None = None,\n",
    "        time_var_names: Sequence[str] | None = None,\n",
    "        layer_type: nn.Module = nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Persist hyperparameters so checkpoints can be reconstructed and inference can run standalone.\n",
    "        self.n_impute_features = n_impute_features\n",
    "        self.n_time_features = n_time_features\n",
    "        self.n_lags = n_lags\n",
    "        self.hidden_sizes = tuple(hidden_sizes)\n",
    "        self.know_whats_hidden = know_whats_hidden\n",
    "        self.lags = tuple(lag_list) if lag_list is not None else tuple(range(1, n_lags + 1))\n",
    "        if len(self.lags) != n_lags:\n",
    "            raise ValueError(\"len(lag_list) must equal n_lags when provided.\")\n",
    "        self.output_lags = (0,) + self.lags\n",
    "        self.n_output_blocks = len(self.output_lags)\n",
    "        self.impute_var_names = tuple(impute_var_names) if impute_var_names else None\n",
    "        self.time_var_names = tuple(time_var_names) if time_var_names else None\n",
    "\n",
    "        self.hidden_flag_width = n_impute_features if know_whats_hidden else 0\n",
    "        self.value_block_width = n_impute_features + n_time_features\n",
    "        self.feature_block_width = self.value_block_width + self.hidden_flag_width\n",
    "        input_dim = self.feature_block_width * (1 + n_lags)\n",
    "        output_dim = n_impute_features * self.n_output_blocks  # current + lagged targets\n",
    "\n",
    "        self.block_slices = {\n",
    "            lag: slice(idx * n_impute_features, (idx + 1) * n_impute_features)\n",
    "            for idx, lag in enumerate(self.output_lags)\n",
    "        }\n",
    "\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            # layers.append(nn.BatchNorm1d(h))  # Add batch normalization\n",
    "            if isinstance(layer_type, type):\n",
    "                layers.append(layer_type())\n",
    "            else:\n",
    "                layers.append(layer_type)\n",
    "            # layers.append(nn.Dropout(0.1))  # Add dropout for regularization\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def _build_feature_matrix(\n",
    "        self,\n",
    "        imputed_vals: np.ndarray,\n",
    "        time_vals: np.ndarray,\n",
    "        mask_vals: np.ndarray | None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Construct current + lagged feature blocks, mirroring the training layout.\"\"\"\n",
    "        n_rows = imputed_vals.shape[0]\n",
    "        features = np.full((n_rows, self.feature_block_width * (1 + self.n_lags)), np.nan, dtype=np.float64)\n",
    "\n",
    "        if time_vals.size:\n",
    "            base_block = np.concatenate([imputed_vals, time_vals], axis=1)\n",
    "        else:\n",
    "            base_block = imputed_vals.copy()\n",
    "\n",
    "        features[:, :self.value_block_width] = base_block\n",
    "\n",
    "        base_hidden = None\n",
    "        if self.know_whats_hidden:\n",
    "            if mask_vals is None:\n",
    "                raise ValueError(\"mask_vals is required when know_whats_hidden=True\")\n",
    "            base_hidden = 1.0 - mask_vals.astype(np.float64, copy=False)\n",
    "            features[:, self.value_block_width:self.feature_block_width] = base_hidden\n",
    "\n",
    "        for idx, lag in enumerate(self.lags, start=1):\n",
    "            block_start = idx * self.feature_block_width\n",
    "            value_dest = features[:, block_start:block_start + self.value_block_width]\n",
    "            if lag < n_rows:\n",
    "                value_dest[lag:] = base_block[:-lag]\n",
    "            if self.know_whats_hidden:\n",
    "                hidden_dest = features[:, block_start + self.value_block_width:block_start + self.feature_block_width]\n",
    "                if lag < n_rows and base_hidden is not None:\n",
    "                    hidden_dest[lag:] = base_hidden[:-lag]\n",
    "\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def _fill_from_prev(arr: np.ndarray, curr_row_idx) -> np.ndarray:\n",
    "        \"\"\"Use the previous row's value if the current value is NaN.\"\"\"\n",
    "        if np.isnan(arr[curr_row_idx - 1]).any():\n",
    "            raise ValueError(f\"Cannot fill row {curr_row_idx} because previous row contains NaN values.\")\n",
    "        mask = np.isnan(arr[curr_row_idx])\n",
    "        arr[curr_row_idx][mask] = arr[curr_row_idx - 1][mask]\n",
    "        return arr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(\n",
    "        self,\n",
    "        history_values: np.ndarray,\n",
    "        curr_row_idx: int,\n",
    "        mutate: bool = True,\n",
    "        clip_range: tuple[float, float] | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        # Debugging checks\n",
    "        if history_values.ndim != 2:\n",
    "            raise ValueError(\"history_values must be a 2D array.\")\n",
    "        n_rows, n_cols = history_values.shape\n",
    "        if n_rows == 0:\n",
    "            raise ValueError(\"history_values must contain at least one row.\")\n",
    "        if n_cols < self.value_block_width:\n",
    "            raise ValueError(\n",
    "                \"history_values must include at least n_impute_features + n_time_features columns.\"\n",
    "            )\n",
    "        if curr_row_idx < 0:\n",
    "            raise IndexError(\"curr_row_idx must be non-negative.\")\n",
    "        if curr_row_idx > n_rows:\n",
    "            raise IndexError(\"curr_row_idx exceeds the number of available rows.\")\n",
    "        \n",
    "        target_idx = curr_row_idx - 1\n",
    "        if target_idx < 0:\n",
    "            raise IndexError(\"curr_row_idx must be at least 1 to expose row 0 for inference.\")\n",
    "\n",
    "        result_array = history_values if mutate else history_values.copy()\n",
    "        impute_block = result_array[:, : self.n_impute_features]\n",
    "        \n",
    "        target_row_vals = impute_block[target_idx]\n",
    "        missing_mask = np.isnan(target_row_vals)\n",
    "        if not np.any(missing_mask):\n",
    "            return result_array\n",
    "\n",
    "        if self.n_time_features:\n",
    "            time_block = result_array[:, self.n_impute_features : self.value_block_width]\n",
    "        else:\n",
    "            time_block = np.zeros((n_rows, 0), dtype=np.float64)\n",
    "\n",
    "        upto_idx = target_idx + 1\n",
    "        values_slice = np.array(impute_block[:upto_idx], dtype=np.float64, copy=False)\n",
    "        time_slice = np.array(time_block[:upto_idx], dtype=np.float64, copy=False)\n",
    "        \n",
    "        values_ffill = self._fill_from_prev(values_slice, len(values_slice) - 1)\n",
    "        \n",
    "        mask_vals = None\n",
    "        if self.know_whats_hidden:\n",
    "            mask_vals = (~np.isnan(values_slice)).astype(np.float64)\n",
    "\n",
    "        features = self._build_feature_matrix(\n",
    "            values_ffill,\n",
    "            time_slice,\n",
    "            mask_vals,\n",
    "        )\n",
    "\n",
    "        feature_row = features[target_idx]\n",
    "        # Fill any NaNs in feature_row with 0 to allow imputation, should not occur\n",
    "        if np.isnan(feature_row).any():\n",
    "            feature_row = np.nan_to_num(feature_row, nan=0.0)\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        feature_tensor = torch.from_numpy(feature_row).double().unsqueeze(0).to(device)\n",
    "        preds = self.net(feature_tensor).cpu().numpy()\n",
    "        if clip_range is not None:\n",
    "            preds = np.clip(preds, clip_range[0], clip_range[1])\n",
    "\n",
    "        current_pred = preds[0, self.block_slices[0]]\n",
    "        impute_block[target_idx, missing_mask] = current_pred[missing_mask]\n",
    "\n",
    "        return result_array\n",
    "\n",
    "    def save_to_disk(self, path: str) -> None:\n",
    "        \"\"\"Serialize model weights and configuration to disk.\"\"\"\n",
    "        checkpoint = {\n",
    "            \"state_dict\": self.state_dict(),\n",
    "            \"config\": {\n",
    "                \"n_impute_features\": self.n_impute_features,\n",
    "                \"n_time_features\": self.n_time_features,\n",
    "                \"n_lags\": self.n_lags,\n",
    "                \"hidden_sizes\": self.hidden_sizes,\n",
    "                \"know_whats_hidden\": self.know_whats_hidden,\n",
    "                \"lag_list\": self.lags,\n",
    "                \"impute_var_names\": self.impute_var_names,\n",
    "                \"time_var_names\": self.time_var_names,\n",
    "            },\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_disk(cls, path: str, map_location: str | torch.device | None = None) -> \"IterativeImputerNet\":\n",
    "        \"\"\"Load a checkpoint produced by save_to_disk.\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=map_location)\n",
    "        if \"config\" not in checkpoint or \"state_dict\" not in checkpoint:\n",
    "            raise ValueError(\"Checkpoint missing required keys 'config' and 'state_dict'.\")\n",
    "        model = cls(**checkpoint[\"config\"])\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31213276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(location):\n",
    "    read_settings = {\n",
    "        \"raise_if_empty\": True,\n",
    "        \"schema_overrides\": {\"Time\": pl.Time}\n",
    "    }\n",
    "    datetime = pl.datetime(\n",
    "        year=pl.col(\"Date\").dt.year(),\n",
    "        month=pl.col(\"Date\").dt.month(),\n",
    "        day=pl.col(\"Date\").dt.day(),\n",
    "        hour=pl.col(\"Time\").dt.hour(),\n",
    "        minute=pl.col(\"Time\").dt.minute(),\n",
    "        second=pl.col(\"Time\").dt.second()\n",
    "    )\n",
    "    return pl.read_excel(location, **read_settings).with_columns(\n",
    "        pl.all().exclude(\"DateTime\", \"Date\", \"Time\").replace(-200, None),\n",
    "        DateTime=datetime,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42c17fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IterativeImputerNet.load_from_disk(\"Model A1.pth\")\n",
    "model.double()\n",
    "model.eval()\n",
    "imputed_data = read_dataset(\"AirQualityUCI.xlsx\").select(\"DateTime\", \"Date\", \"Time\").hstack(pl.read_ipc(\"Model A1 full imputed dataset.parquet\"))\n",
    "original_with_still_missing_values = pl.read_ipc(\"missing_normalised_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cde1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection(\n",
    "    original_with_still_missing_values: pl.DataFrame,\n",
    "    imputed_data: pl.DataFrame,\n",
    "    variable: str,\n",
    "    threshold: float = 3.0\n",
    ") -> pl.DataFrame:\n",
    "    # Get the columns the model expects\n",
    "    impute_vars = list(model.impute_var_names) if model.impute_var_names else []\n",
    "    time_vars = list(model.time_var_names) if model.time_var_names else []\n",
    "    model_columns = impute_vars + time_vars\n",
    "    \n",
    "    # Select only the columns the model uses\n",
    "    imputed_np = imputed_data.select(model_columns).to_numpy().copy()\n",
    "    var_idx = impute_vars.index(variable)\n",
    "    \n",
    "    value_differences = {}\n",
    "    for i in range(4, len(imputed_data)):\n",
    "        # Check if the variable value at row i is not missing in original_with_still_missing_values\n",
    "        if original_with_still_missing_values[i, variable] is not None and not np.isnan(original_with_still_missing_values[i, variable]):\n",
    "            # Store the real value\n",
    "            real_val = imputed_data[i, variable]\n",
    "            \n",
    "            # Hide the variable value at row i\n",
    "            imputed_np[i, var_idx] = np.nan\n",
    "            \n",
    "            # Impute the variable value at row i using the model\n",
    "            model.predict(imputed_np, i + 1, mutate=True)\n",
    "            \n",
    "            # Get the imputed value\n",
    "            imputed_val = imputed_np[i, var_idx]\n",
    "            \n",
    "            # Compute difference\n",
    "            diff = imputed_val - real_val\n",
    "            \n",
    "            # Store: value_differences[DateTime] = (imputed value, real value, difference)\n",
    "            datetime_val = imputed_data[i, \"DateTime\"]\n",
    "            value_differences[datetime_val] = (imputed_val, real_val, diff)\n",
    "            \n",
    "            # Restore the original value back into imputed_np\n",
    "            imputed_np[i, var_idx] = real_val\n",
    "    \n",
    "    # Compute the mean and stddev of the differences\n",
    "    if not value_differences:\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    diffs = [v[2] for v in value_differences.values()]\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs)\n",
    "    \n",
    "    # Return any tuples where the difference is more than threshold * stddev away from the mean\n",
    "    anomalies = []\n",
    "    for dt, (imp, real, diff) in value_differences.items():\n",
    "        if abs(diff - mean_diff) > threshold * std_diff:\n",
    "            anomalies.append({\"DateTime\": dt, \"imputed\": imp, \"real\": real, \"difference\": diff})\n",
    "    \n",
    "    return pl.DataFrame(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea3cf04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DateTime',\n",
       " 'Date',\n",
       " 'Time',\n",
       " 'linear_dt',\n",
       " 'sin_time_of_year',\n",
       " 'cos_time_of_year',\n",
       " 'is_mon',\n",
       " 'is_tue',\n",
       " 'is_wed',\n",
       " 'is_thu',\n",
       " 'is_fri',\n",
       " 'is_sat',\n",
       " 'is_sun',\n",
       " 'is_weekday',\n",
       " 'sin_time_of_week',\n",
       " 'cos_time_of_week',\n",
       " 'sin_hour_of_day',\n",
       " 'cos_hour_of_day',\n",
       " 'CO(GT)',\n",
       " 'PT08.S1(CO)',\n",
       " 'NMHC(GT)',\n",
       " 'C6H6(GT)',\n",
       " 'PT08.S2(NMHC)',\n",
       " 'NOx(GT)',\n",
       " 'PT08.S3(NOx)',\n",
       " 'NO2(GT)',\n",
       " 'PT08.S4(NO2)',\n",
       " 'PT08.S5(O3)',\n",
       " 'T',\n",
       " 'RH',\n",
       " 'AH']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.schema.names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ac8794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'CO(GT)',\n",
    "    'PT08.S1(CO)',\n",
    "    'NMHC(GT)',\n",
    "    'C6H6(GT)',\n",
    "    'PT08.S2(NMHC)',\n",
    "    'NOx(GT)',\n",
    "    'PT08.S3(NOx)',\n",
    "    'NO2(GT)',\n",
    "    'PT08.S4(NO2)',\n",
    "    'PT08.S5(O3)',\n",
    "    'T',\n",
    "    'RH',\n",
    "    'AH'\n",
    "]\n",
    "\n",
    "anomalies = {}\n",
    "for var in variables:\n",
    "    anomalies[var] = anomaly_detection(\n",
    "        original_with_still_missing_values,\n",
    "        imputed_data,\n",
    "        var,\n",
    "        threshold=4.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dca9a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO(GT)\n",
      "2004-11-21 08:00:00\n",
      "2004-11-22 06:00:00\n",
      "2004-11-22 07:00:00\n",
      "2005-01-10 07:00:00\n",
      "2005-01-19 07:00:00\n",
      "2005-01-24 02:00:00\n",
      "2005-03-11 07:00:00\n",
      "2005-03-12 08:00:00\n",
      "2005-03-12 09:00:00\n",
      "2005-03-13 09:00:00\n",
      "\n",
      "\n",
      "PT08.S1(CO)\n",
      "2004-06-21 04:00:00\n",
      "2005-02-13 01:00:00\n",
      "\n",
      "\n",
      "NMHC(GT)\n",
      "No anomalies detected\n",
      "\n",
      "\n",
      "C6H6(GT)\n",
      "2004-11-22 09:00:00\n",
      "2004-11-22 10:00:00\n",
      "2005-02-14 11:00:00\n",
      "\n",
      "\n",
      "PT08.S2(NMHC)\n",
      "2004-11-22 09:00:00\n",
      "2004-11-22 10:00:00\n",
      "2005-02-14 11:00:00\n",
      "\n",
      "\n",
      "NOx(GT)\n",
      "No anomalies detected\n",
      "\n",
      "\n",
      "PT08.S3(NOx)\n",
      "2004-12-01 06:00:00\n",
      "2004-12-01 07:00:00\n",
      "2004-12-10 07:00:00\n",
      "2004-12-10 08:00:00\n",
      "2004-12-10 09:00:00\n",
      "2004-12-10 11:00:00\n",
      "2005-02-11 21:00:00\n",
      "\n",
      "\n",
      "NO2(GT)\n",
      "No anomalies detected\n",
      "\n",
      "\n",
      "PT08.S4(NO2)\n",
      "2004-04-01 18:00:00\n",
      "2004-11-23 18:00:00\n",
      "2004-11-23 19:00:00\n",
      "2004-11-23 20:00:00\n",
      "2005-01-24 03:00:00\n",
      "2005-01-29 02:00:00\n",
      "\n",
      "\n",
      "PT08.S5(O3)\n",
      "2004-11-01 00:00:00\n",
      "2004-12-23 19:00:00\n",
      "2005-01-01 01:00:00\n",
      "2005-01-31 20:00:00\n",
      "2005-02-12 23:00:00\n",
      "2005-02-13 00:00:00\n",
      "2005-03-02 20:00:00\n",
      "\n",
      "\n",
      "T\n",
      "2004-11-21 07:00:00\n",
      "2004-11-22 05:00:00\n",
      "2004-12-23 04:00:00\n",
      "2005-01-23 06:00:00\n",
      "2005-02-02 23:00:00\n",
      "2005-02-05 06:00:00\n",
      "2005-02-06 04:00:00\n",
      "2005-02-06 05:00:00\n",
      "2005-02-06 06:00:00\n",
      "2005-02-06 07:00:00\n",
      "2005-02-06 09:00:00\n",
      "2005-02-27 06:00:00\n",
      "2005-02-28 21:00:00\n",
      "2005-02-28 22:00:00\n",
      "2005-02-28 23:00:00\n",
      "2005-03-01 00:00:00\n",
      "2005-03-01 01:00:00\n",
      "2005-03-01 02:00:00\n",
      "2005-03-01 03:00:00\n",
      "2005-03-01 04:00:00\n",
      "2005-03-01 05:00:00\n",
      "2005-03-01 06:00:00\n",
      "2005-03-01 07:00:00\n",
      "2005-03-01 22:00:00\n",
      "2005-03-01 23:00:00\n",
      "2005-03-02 00:00:00\n",
      "2005-03-02 01:00:00\n",
      "2005-03-02 02:00:00\n",
      "2005-03-02 03:00:00\n",
      "2005-03-02 04:00:00\n",
      "2005-03-02 05:00:00\n",
      "2005-03-02 06:00:00\n",
      "2005-03-02 07:00:00\n",
      "2005-03-02 08:00:00\n",
      "2005-03-08 03:00:00\n",
      "2005-03-08 04:00:00\n",
      "\n",
      "\n",
      "RH\n",
      "2004-11-07 23:00:00\n",
      "2004-11-08 00:00:00\n",
      "2005-01-14 23:00:00\n",
      "2005-01-31 11:00:00\n",
      "2005-02-14 07:00:00\n",
      "2005-03-02 09:00:00\n",
      "2005-03-03 09:00:00\n",
      "2005-03-03 11:00:00\n",
      "2005-03-08 09:00:00\n",
      "\n",
      "\n",
      "AH\n",
      "2004-11-19 21:00:00\n",
      "2004-11-22 10:00:00\n",
      "2004-11-22 11:00:00\n",
      "2004-11-22 19:00:00\n",
      "2004-11-22 21:00:00\n",
      "2005-01-17 19:00:00\n",
      "2005-01-17 20:00:00\n",
      "2005-01-22 15:00:00\n",
      "2005-01-22 22:00:00\n",
      "2005-01-31 19:00:00\n",
      "2005-01-31 20:00:00\n",
      "2005-01-31 21:00:00\n",
      "2005-02-16 09:00:00\n",
      "2005-03-02 21:00:00\n",
      "2005-03-03 09:00:00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in variables:\n",
    "    print(var)\n",
    "    if len(anomalies[var]):\n",
    "        for date in anomalies[var].select(\"DateTime\").to_series().to_list():\n",
    "            print(date)\n",
    "    else:\n",
    "        print(\"No anomalies detected\")\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
