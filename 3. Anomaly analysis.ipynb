{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a401720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: polars in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 2)) (1.35.2)\n",
      "Requirement already satisfied: fastexcel in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 3)) (0.17.2)\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 4)) (22.0.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 5)) (3.10.7)\n",
      "Requirement already satisfied: holidays in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 6)) (0.85)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 7)) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: polarify in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 10)) (0.2.1)\n",
      "Requirement already satisfied: livelossplot in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 11)) (0.5.6)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 12)) (2.3.5)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.14/site-packages (from -r requirements.txt (line 13)) (2.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.14/site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.2 in ./.venv/lib/python3.14/site-packages (from polars->-r requirements.txt (line 2)) (1.35.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.14/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: bokeh in ./.venv/lib/python3.14/site-packages (from livelossplot->-r requirements.txt (line 11)) (3.8.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.14/site-packages (from torch->-r requirements.txt (line 13)) (3.5.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.14/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.13 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (2.12.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (6.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (6.5.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in ./.venv/lib/python3.14/site-packages (from bokeh->livelossplot->-r requirements.txt (line 11)) (2025.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.14/site-packages (from jinja2->torch->-r requirements.txt (line 13)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba518a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from livelossplot import PlotLosses\n",
    "import random\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb6da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeImputerNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_impute_features: int,\n",
    "        n_time_features: int,\n",
    "        n_lags: int,\n",
    "        hidden_sizes: Sequence[int] = (128, 64),\n",
    "        know_whats_hidden: bool = False,\n",
    "        lag_list: Sequence[int] | None = None,\n",
    "        impute_var_names: Sequence[str] | None = None,\n",
    "        time_var_names: Sequence[str] | None = None,\n",
    "        layer_type: nn.Module = nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Persist hyperparameters so checkpoints can be reconstructed and inference can run standalone.\n",
    "        self.n_impute_features = n_impute_features\n",
    "        self.n_time_features = n_time_features\n",
    "        self.n_lags = n_lags\n",
    "        self.hidden_sizes = tuple(hidden_sizes)\n",
    "        self.know_whats_hidden = know_whats_hidden\n",
    "        self.lags = tuple(lag_list) if lag_list is not None else tuple(range(1, n_lags + 1))\n",
    "        if len(self.lags) != n_lags:\n",
    "            raise ValueError(\"len(lag_list) must equal n_lags when provided.\")\n",
    "        self.output_lags = (0,) + self.lags\n",
    "        self.n_output_blocks = len(self.output_lags)\n",
    "        self.impute_var_names = tuple(impute_var_names) if impute_var_names else None\n",
    "        self.time_var_names = tuple(time_var_names) if time_var_names else None\n",
    "\n",
    "        self.hidden_flag_width = n_impute_features if know_whats_hidden else 0\n",
    "        self.value_block_width = n_impute_features + n_time_features\n",
    "        self.feature_block_width = self.value_block_width + self.hidden_flag_width\n",
    "        input_dim = self.feature_block_width * (1 + n_lags)\n",
    "        output_dim = n_impute_features * self.n_output_blocks  # current + lagged targets\n",
    "\n",
    "        self.block_slices = {\n",
    "            lag: slice(idx * n_impute_features, (idx + 1) * n_impute_features)\n",
    "            for idx, lag in enumerate(self.output_lags)\n",
    "        }\n",
    "\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            # layers.append(nn.BatchNorm1d(h))  # Add batch normalization\n",
    "            if isinstance(layer_type, type):\n",
    "                layers.append(layer_type())\n",
    "            else:\n",
    "                layers.append(layer_type)\n",
    "            # layers.append(nn.Dropout(0.1))  # Add dropout for regularization\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def _build_feature_matrix(\n",
    "        self,\n",
    "        imputed_vals: np.ndarray,\n",
    "        time_vals: np.ndarray,\n",
    "        mask_vals: np.ndarray | None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Construct current + lagged feature blocks, mirroring the training layout.\"\"\"\n",
    "        n_rows = imputed_vals.shape[0]\n",
    "        features = np.full((n_rows, self.feature_block_width * (1 + self.n_lags)), np.nan, dtype=np.float64)\n",
    "\n",
    "        if time_vals.size:\n",
    "            base_block = np.concatenate([imputed_vals, time_vals], axis=1)\n",
    "        else:\n",
    "            base_block = imputed_vals.copy()\n",
    "\n",
    "        features[:, :self.value_block_width] = base_block\n",
    "\n",
    "        base_hidden = None\n",
    "        if self.know_whats_hidden:\n",
    "            if mask_vals is None:\n",
    "                raise ValueError(\"mask_vals is required when know_whats_hidden=True\")\n",
    "            base_hidden = 1.0 - mask_vals.astype(np.float64, copy=False)\n",
    "            features[:, self.value_block_width:self.feature_block_width] = base_hidden\n",
    "\n",
    "        for idx, lag in enumerate(self.lags, start=1):\n",
    "            block_start = idx * self.feature_block_width\n",
    "            value_dest = features[:, block_start:block_start + self.value_block_width]\n",
    "            if lag < n_rows:\n",
    "                value_dest[lag:] = base_block[:-lag]\n",
    "            if self.know_whats_hidden:\n",
    "                hidden_dest = features[:, block_start + self.value_block_width:block_start + self.feature_block_width]\n",
    "                if lag < n_rows and base_hidden is not None:\n",
    "                    hidden_dest[lag:] = base_hidden[:-lag]\n",
    "\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def _fill_from_prev(arr: np.ndarray, curr_row_idx) -> np.ndarray:\n",
    "        \"\"\"Use the previous row's value if the current value is NaN.\"\"\"\n",
    "        if np.isnan(arr[curr_row_idx - 1]).any():\n",
    "            raise ValueError(f\"Cannot fill row {curr_row_idx} because previous row contains NaN values.\")\n",
    "        mask = np.isnan(arr[curr_row_idx])\n",
    "        arr[curr_row_idx][mask] = arr[curr_row_idx - 1][mask]\n",
    "        return arr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(\n",
    "        self,\n",
    "        history_values: np.ndarray,\n",
    "        curr_row_idx: int,\n",
    "        mutate: bool = True,\n",
    "        clip_range: tuple[float, float] | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        # Debugging checks\n",
    "        if history_values.ndim != 2:\n",
    "            raise ValueError(\"history_values must be a 2D array.\")\n",
    "        n_rows, n_cols = history_values.shape\n",
    "        if n_rows == 0:\n",
    "            raise ValueError(\"history_values must contain at least one row.\")\n",
    "        if n_cols < self.value_block_width:\n",
    "            raise ValueError(\n",
    "                \"history_values must include at least n_impute_features + n_time_features columns.\"\n",
    "            )\n",
    "        if curr_row_idx < 0:\n",
    "            raise IndexError(\"curr_row_idx must be non-negative.\")\n",
    "        if curr_row_idx > n_rows:\n",
    "            raise IndexError(\"curr_row_idx exceeds the number of available rows.\")\n",
    "        \n",
    "        target_idx = curr_row_idx - 1\n",
    "        if target_idx < 0:\n",
    "            raise IndexError(\"curr_row_idx must be at least 1 to expose row 0 for inference.\")\n",
    "\n",
    "        result_array = history_values if mutate else history_values.copy()\n",
    "        impute_block = result_array[:, : self.n_impute_features]\n",
    "        \n",
    "        target_row_vals = impute_block[target_idx]\n",
    "        missing_mask = np.isnan(target_row_vals)\n",
    "        if not np.any(missing_mask):\n",
    "            return result_array\n",
    "\n",
    "        if self.n_time_features:\n",
    "            time_block = result_array[:, self.n_impute_features : self.value_block_width]\n",
    "        else:\n",
    "            time_block = np.zeros((n_rows, 0), dtype=np.float64)\n",
    "\n",
    "        upto_idx = target_idx + 1\n",
    "        values_slice = np.array(impute_block[:upto_idx], dtype=np.float64, copy=False)\n",
    "        time_slice = np.array(time_block[:upto_idx], dtype=np.float64, copy=False)\n",
    "        \n",
    "        values_ffill = self._fill_from_prev(values_slice, len(values_slice) - 1)\n",
    "        \n",
    "        mask_vals = None\n",
    "        if self.know_whats_hidden:\n",
    "            mask_vals = (~np.isnan(values_slice)).astype(np.float64)\n",
    "\n",
    "        features = self._build_feature_matrix(\n",
    "            values_ffill,\n",
    "            time_slice,\n",
    "            mask_vals,\n",
    "        )\n",
    "\n",
    "        feature_row = features[target_idx]\n",
    "        # Fill any NaNs in feature_row with 0 to allow imputation, should not occur\n",
    "        if np.isnan(feature_row).any():\n",
    "            feature_row = np.nan_to_num(feature_row, nan=0.0)\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        feature_tensor = torch.from_numpy(feature_row).double().unsqueeze(0).to(device)\n",
    "        preds = self.net(feature_tensor).cpu().numpy()\n",
    "        if clip_range is not None:\n",
    "            preds = np.clip(preds, clip_range[0], clip_range[1])\n",
    "\n",
    "        current_pred = preds[0, self.block_slices[0]]\n",
    "        impute_block[target_idx, missing_mask] = current_pred[missing_mask]\n",
    "\n",
    "        return result_array\n",
    "\n",
    "    def save_to_disk(self, path: str) -> None:\n",
    "        \"\"\"Serialize model weights and configuration to disk.\"\"\"\n",
    "        checkpoint = {\n",
    "            \"state_dict\": self.state_dict(),\n",
    "            \"config\": {\n",
    "                \"n_impute_features\": self.n_impute_features,\n",
    "                \"n_time_features\": self.n_time_features,\n",
    "                \"n_lags\": self.n_lags,\n",
    "                \"hidden_sizes\": self.hidden_sizes,\n",
    "                \"know_whats_hidden\": self.know_whats_hidden,\n",
    "                \"lag_list\": self.lags,\n",
    "                \"impute_var_names\": self.impute_var_names,\n",
    "                \"time_var_names\": self.time_var_names,\n",
    "            },\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_disk(cls, path: str, map_location: str | torch.device | None = None) -> \"IterativeImputerNet\":\n",
    "        \"\"\"Load a checkpoint produced by save_to_disk.\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=map_location)\n",
    "        if \"config\" not in checkpoint or \"state_dict\" not in checkpoint:\n",
    "            raise ValueError(\"Checkpoint missing required keys 'config' and 'state_dict'.\")\n",
    "        model = cls(**checkpoint[\"config\"])\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31213276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(location):\n",
    "    read_settings = {\n",
    "        \"raise_if_empty\": True,\n",
    "        \"schema_overrides\": {\"Time\": pl.Time}\n",
    "    }\n",
    "    datetime = pl.datetime(\n",
    "        year=pl.col(\"Date\").dt.year(),\n",
    "        month=pl.col(\"Date\").dt.month(),\n",
    "        day=pl.col(\"Date\").dt.day(),\n",
    "        hour=pl.col(\"Time\").dt.hour(),\n",
    "        minute=pl.col(\"Time\").dt.minute(),\n",
    "        second=pl.col(\"Time\").dt.second()\n",
    "    )\n",
    "    return pl.read_excel(location, **read_settings).with_columns(\n",
    "        pl.all().exclude(\"DateTime\", \"Date\", \"Time\").replace(-200, None),\n",
    "        DateTime=datetime,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c17fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IterativeImputerNet.load_from_disk(\"Model A1.pth\")\n",
    "imputed_data = read_dataset(\"AirQualityUCI.xlsx\").select(\"DateTime\", \"Date\", \"Time\").hstack(pl.read_ipc(\"Model A1 full imputed dataset.parquet\"))\n",
    "original_with_still_missing_values = pl.read_ipc(\"missing_normalised_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde1dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     49\u001b[39m             anomalies.append({\u001b[33m\"\u001b[39m\u001b[33mDateTime\u001b[39m\u001b[33m\"\u001b[39m: dt, \u001b[33m\"\u001b[39m\u001b[33mimputed\u001b[39m\u001b[33m\"\u001b[39m: imp, \u001b[33m\"\u001b[39m\u001b[33mreal\u001b[39m\u001b[33m\"\u001b[39m: real, \u001b[33m\"\u001b[39m\u001b[33mdifference\u001b[39m\u001b[33m\"\u001b[39m: diff})\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pl.DataFrame(anomalies)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43manomaly_detection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43moriginal_with_still_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimputed_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCO(GT)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.0\u001b[39;49m\n\u001b[32m     58\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36manomaly_detection\u001b[39m\u001b[34m(original_with_still_missing_values, imputed_data, variable, threshold)\u001b[39m\n\u001b[32m     19\u001b[39m imputed_np[i, var_idx] = np.nan\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Impute the variable value at row i using the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputed_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Get the imputed value\u001b[39;00m\n\u001b[32m     25\u001b[39m imputed_val = imputed_np[i, var_idx]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UNSW/2025 Term 3/COMP9417 Machine Learning/Group assignment final code/.venv/lib/python3.14/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mIterativeImputerNet.predict\u001b[39m\u001b[34m(self, history_values, curr_row_idx, mutate, clip_range)\u001b[39m\n\u001b[32m    130\u001b[39m impute_block = result_array[:, : \u001b[38;5;28mself\u001b[39m.n_impute_features]\n\u001b[32m    132\u001b[39m target_row_vals = impute_block[target_idx]\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m missing_mask = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_row_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.any(missing_mask):\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_array\n",
      "\u001b[31mTypeError\u001b[39m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "def anomaly_detection(\n",
    "    original_with_still_missing_values: pl.DataFrame,\n",
    "    imputed_data: pl.DataFrame,\n",
    "    variable: str,\n",
    "    threshold: float = 3.0\n",
    ") -> pl.DataFrame:\n",
    "    # Get the columns the model expects\n",
    "    impute_vars = list(model.impute_var_names) if model.impute_var_names else []\n",
    "    time_vars = list(model.time_var_names) if model.time_var_names else []\n",
    "    model_columns = impute_vars + time_vars\n",
    "    \n",
    "    # Select only the columns the model uses\n",
    "    imputed_np = imputed_data.select(model_columns).to_numpy().copy()\n",
    "    var_idx = impute_vars.index(variable)\n",
    "    \n",
    "    value_differences = {}\n",
    "    for i in range(len(imputed_data)):\n",
    "        # Check if the variable value at row i is not missing in original_with_still_missing_values\n",
    "        if original_with_still_missing_values[i, variable] is not None and not np.isnan(original_with_still_missing_values[i, variable]):\n",
    "            # Store the real value\n",
    "            real_val = imputed_data[i, variable]\n",
    "            \n",
    "            # Hide the variable value at row i\n",
    "            imputed_np[i, var_idx] = np.nan\n",
    "            \n",
    "            # Impute the variable value at row i using the model\n",
    "            model.predict(imputed_np, i + 1, mutate=True)\n",
    "            \n",
    "            # Get the imputed value\n",
    "            imputed_val = imputed_np[i, var_idx]\n",
    "            \n",
    "            # Compute difference\n",
    "            diff = imputed_val - real_val\n",
    "            \n",
    "            # Store: value_differences[DateTime] = (imputed value, real value, difference)\n",
    "            datetime_val = imputed_data[i, \"DateTime\"]\n",
    "            value_differences[datetime_val] = (imputed_val, real_val, diff)\n",
    "            \n",
    "            # Restore the original value back into imputed_np\n",
    "            imputed_np[i, var_idx] = real_val\n",
    "    \n",
    "    # Compute the mean and stddev of the differences\n",
    "    if not value_differences:\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    diffs = [v[2] for v in value_differences.values()]\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs)\n",
    "    \n",
    "    # Return any tuples where the difference is more than threshold * stddev away from the mean\n",
    "    anomalies = []\n",
    "    for dt, (imp, real, diff) in value_differences.items():\n",
    "        if abs(diff - mean_diff) > threshold * std_diff:\n",
    "            anomalies.append({\"DateTime\": dt, \"imputed\": imp, \"real\": real, \"difference\": diff})\n",
    "    \n",
    "    return pl.DataFrame(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8794a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting_index = 4\n",
    "# reimputed_data = (\n",
    "#     imputed_df.slice(0, starting_index)\n",
    "#     .vstack(\n",
    "#         norm_training_data.slice(starting_index)\n",
    "#     ).select(extended_variables)\n",
    "# ).to_numpy()\n",
    "# for i in range(starting_index, len(imputed_df)):\n",
    "#     model.predict(reimputed_data, i + 1, mutate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85e41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
